# IGT-MFG: Iterative Generator Training for Mean Field Games

This repository contains the code used in our work:

**"INITIALIZATION-DRIVEN NEURAL GENERATION AND TRAINING FOR
HIGH-DIMENSIONAL OPTIMAL CONTROL AND FIRST-ORDER MEAN FIELD
GAMES"**  
üìÑ [arXiv:2507.15126](https://arxiv.org/pdf/2507.15126)

## üìå Overview

We propose a framework based on neural network approximation for solving mean field games (MFG) using a generator-based population simulator. The method alternates between solving Hamilton-Jacobi-Bellman (HJB) equations and training generators to match population distributions.

This code includes:
- Initialisation "HJB solver" using DGM
- Best response generation using TPBVP solvers
- Neural generator training and simulation
- Evaluation of exploitability and Wasserstein distance

## üîß Structure

- `main.py` ‚Äî Training and evaluation pipeline
- `model.py` ‚Äî Neural network architectures (V_Net and G_Net)
- `src/solve.py` ‚Äî Training routines for HJB, TPBVP, and generator
- `src/problem/prb.py` ‚Äî problem definitions (dynamics, costs, etc.)

## üìÑ Paper

üìù If you're interested in the full theoretical and experimental details, please see our paper:  
**[INITIALIZATION-DRIVEN NEURAL GENERATION AND TRAINING FOR
HIGH-DIMENSIONAL OPTIMAL CONTROL AND FIRST-ORDER MEAN FIELD
GAMES](https://arxiv.org/pdf/2507.15126)**


